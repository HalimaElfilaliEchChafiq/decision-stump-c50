import nbformat as nbf
import os

def create_notebook():
    nb = nbf.v4.new_notebook()
    
    # --- CELLULE 1 : Titre ---
    text_1 = """\
# üèÜ R√©sultats Finaux : Decision Stump C5.0
**Projet Knowledge Data Discovery (2025-2026)**
*Auteurs : Groupe M*

Ce notebook pr√©sente l'√©valuation finale de notre impl√©mentation du **Decision Stump** bas√© sur l'algorithme **C5.0**.
Nous utilisons le crit√®re du **Gain Ratio** et une gestion pond√©r√©e des valeurs manquantes.

### Objectifs :
1. Charger les donn√©es brutes (Iris).
2. Entra√Æner le mod√®le C5.0 (Profondeur 1).
3. √âvaluer les performances (Accuracy, F1-Score).
4. Visualiser la fronti√®re de d√©cision et la matrice de confusion."""
    
    # --- CELLULE 2 : Imports ---
    code_2 = """\
import sys
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Configuration du chemin pour acc√©der √† 'src'
sys.path.append(os.path.abspath('..'))

# Importation de notre package
from src.stump import DecisionStump
from src.metrics import accuracy, f1_score_macro, confusion_matrix

%matplotlib inline
plt.style.use('seaborn-v0_8-whitegrid')
print("‚úÖ Environnement charg√©.")"""

    # --- CELLULE 3 : Chargement des Donn√©es ---
    text_3 = """## 1. Chargement et Pr√©paration des Donn√©es"""
    code_3 = """\
# Chargement direct depuis le CSV Raw
data_path = '../data/raw/iris.csv'
df = pd.read_csv(data_path)

print(f"Dataset charg√© : {df.shape[0]} exemples, {df.shape[1]} colonnes")
display(df.head())

# S√©paration Features / Target
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values
feature_names = df.columns[:-1]

# Split Train/Test (70/30)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}")"""

    # --- CELLULE 4 : Entra√Ænement ---
    text_4 = """## 2. Entra√Ænement du Mod√®le (C5.0)
Nous utilisons ici le crit√®re **'gain_ratio'**, sp√©cifique √† C5.0 (contrairement √† ID3 qui utilise le Gain d'Information simple)."""
    code_4 = """\
# Initialisation du mod√®le Stump C5.0
model = DecisionStump(criterion='gain_ratio')

# Entra√Ænement
print("üîÑ Entra√Ænement en cours...")
model.fit(X_train, y_train)

# Affichage de la r√®gle d√©couverte
if model.feature_index_ is not None:
    feat = feature_names[model.feature_index_]
    seuil = model.threshold_
    print(f"\\n‚úÖ R√®gle Optimale Trouv√©e :")
    print(f"   SI {feat} <= {seuil:.2f} ALORS Classe Gauche")
    print(f"   SINON Classe Droite")
    print(f"   (Gain Ratio: {model.split_type_})")
else:
    print("Mod√®le constant.")"""

    # --- CELLULE 5 : √âvaluation ---
    text_5 = """## 3. √âvaluation des Performances
Nous utilisons l'**Accuracy** (pr√©cision globale) et le **F1-Score Macro** (moyenne harmonique, utile si d√©s√©quilibre)."""
    code_5 = """\
# Pr√©diction sur le test set
y_pred = model.predict(X_test)

# Calcul des m√©triques
acc = accuracy(y_test, y_pred)
f1 = f1_score_macro(y_test, y_pred)

print(f"üèÜ R√âSULTATS SUR TEST :")
print(f"   Accuracy : {acc:.2%}")
print(f"   F1-Score : {f1:.2%} (Macro)")"""

    # --- CELLULE 6 : Visualisation Matrice Confusion ---
    text_6 = """## 4. Visualisations
### 4.1 Matrice de Confusion"""
    code_6 = """\
# G√©n√©ration de la matrice
cm_df = confusion_matrix(y_test, y_pred)

# Affichage
plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.title('Matrice de Confusion (Iris Test)')
plt.ylabel('Vraie Classe')
plt.xlabel('Classe Pr√©dite')
plt.show()"""

    # --- CELLULE 7 : Fronti√®re de D√©cision ---
    text_7 = """### 4.2 Fronti√®re de D√©cision (2D)
Pour visualiser la coupure, nous r√©-entra√Ænons un Stump sur les deux meilleures features uniquement (g√©n√©ralement Longueur/Largeur P√©tale)."""
    code_7 = """\
def plot_boundary(X, y, model_class):
    # On garde seulement les features 2 et 3 (Petal Length/Width) pour la visu
    X_pair = X[:, [2, 3]]
    
    # Encodage num√©rique pour l'affichage
    le = LabelEncoder()
    y_enc = le.fit_transform(y)
    
    # Entra√Ænement visu
    clf = model_class(criterion='gain_ratio')
    clf.fit(X_pair, y) # Le mod√®le g√®re les labels texte, mais le plot veut des nombres
    
    # Grille
    x_min, x_max = X_pair[:, 0].min() - 1, X_pair[:, 0].max() + 1
    y_min, y_max = X_pair[:, 1].min() - 1, X_pair[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.05),
                         np.arange(y_min, y_max, 0.05))
    
    # Pred
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = le.transform(Z).reshape(xx.shape)
    
    plt.figure(figsize=(10, 6))
    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis')
    plt.scatter(X_pair[:, 0], X_pair[:, 1], c=y_enc, s=50, edgecolor='k', cmap='viridis')
    plt.xlabel('Petal Length')
    plt.ylabel('Petal Width')
    plt.title(f"Fronti√®re de D√©cision C5.0 Stump\\n(Split: {clf.threshold_:.2f})")
    plt.show()

plot_boundary(X, y, DecisionStump)"""

    # --- Construction du Notebook ---
    nb['cells'] = [
        nbf.v4.new_markdown_cell(text_1),
        nbf.v4.new_code_cell(code_2),
        nbf.v4.new_markdown_cell(text_3),
        nbf.v4.new_code_cell(code_3),
        nbf.v4.new_markdown_cell(text_4),
        nbf.v4.new_code_cell(code_4),
        nbf.v4.new_markdown_cell(text_5),
        nbf.v4.new_code_cell(code_5),
        nbf.v4.new_markdown_cell(text_6),
        nbf.v4.new_code_cell(code_6),
        nbf.v4.new_markdown_cell(text_7),
        nbf.v4.new_code_cell(code_7)
    ]

    # Sauvegarde
    os.makedirs('notebooks', exist_ok=True)
    with open('notebooks/02_final_results.ipynb', 'w', encoding='utf-8') as f:
        nbf.write(nb, f)
    
    print("‚úÖ Notebook 'notebooks/02_final_results.ipynb' g√©n√©r√© avec succ√®s !")

if __name__ == "__main__":
    create_notebook()